{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data()\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "# O model será exportado para este arquivo\n",
    "filename='mnistneuralnet.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(60, (26, 26), input_shape=(1, 28, 28), activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(30, (15, 15), input_shape=(1, 28, 28), activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(15, (8, 8), input_shape=(1, 28, 28), activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax', name='predict'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 15 from 1 for 'conv2d_22/convolution' (op: 'Conv2D') with input shapes: [?,1,1,60], [15,15,60,30].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 15 from 1 for 'conv2d_22/convolution' (op: 'Conv2D') with input shapes: [?,1,1,60], [15,15,60,30].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f83b1548ef06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-8addeb04fb15>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3648\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3649\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3650\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         data_format=data_format)\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m   1027\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 15 from 1 for 'conv2d_22/convolution' (op: 'Conv2D') with input shapes: [?,1,1,60], [15,15,60,30]."
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jimi/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.8747 - acc: 0.7047 - val_loss: 0.2516 - val_acc: 0.9217\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 29s 490us/step - loss: 0.3663 - acc: 0.8816 - val_loss: 0.1726 - val_acc: 0.9460\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.2936 - acc: 0.9030 - val_loss: 0.1498 - val_acc: 0.9547\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.2562 - acc: 0.9158 - val_loss: 0.1222 - val_acc: 0.9609\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 0.2362 - acc: 0.9227 - val_loss: 0.1207 - val_acc: 0.9632\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 25s 409us/step - loss: 0.2124 - acc: 0.9313 - val_loss: 0.1122 - val_acc: 0.9660\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 24s 392us/step - loss: 0.2013 - acc: 0.9344 - val_loss: 0.0961 - val_acc: 0.9696\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 24s 394us/step - loss: 0.1894 - acc: 0.9386 - val_loss: 0.0913 - val_acc: 0.9726\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.1826 - acc: 0.9413 - val_loss: 0.0867 - val_acc: 0.9720\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 24s 392us/step - loss: 0.1727 - acc: 0.9439 - val_loss: 0.0881 - val_acc: 0.9722\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200)\n",
    "model.save_weights(filename)\n",
    "\n",
    "model.load_weights('./{}'.format(filename) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 97.22%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"\\nacc: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faa69f30048>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_pred = cv2.imread(\"number-five.png\", 0)\n",
    "plt.imshow(img_pred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if img_pred.shape != [28,28]:\n",
    "    img2 = cv2.resize(img_pred, (28, 28))\n",
    "    img_pred = img2.reshape(28, 28, -1)\n",
    "else:\n",
    "    img_pred = img_pred.reshape(28, 28, -1)\n",
    "\n",
    "\n",
    "img_pred = img_pred.reshape(1, 1, 28, 28).astype('float32')\n",
    "\n",
    "img_pred = img_pred/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  com confiança de  39.21%\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(img_pred)\n",
    "pred_proba = model.predict_proba(img_pred)\n",
    "pred_proba = \"%.2f%%\" % (pred_proba[0][pred]*100)\n",
    "print(pred[0], \" com confiança de \", pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
